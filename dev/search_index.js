var documenterSearchIndex = {"docs":
[{"location":"references/#References","page":"References","title":"References","text":"D.-H. Li and M. Fukushima. A derivative-free line search and global convergence of Broyden-like method for nonlinear equations. Optimization methods and software 13, 181–201 (2000).\n\n\n\nW. La Cruz, J. Martı́nez and M. Raydan. Spectral residual method without gradient information for solving large-scale nonlinear systems of equations. Mathematics of computation 75, 1429–1448 (2006).\n\n\n\n","category":"section"},{"location":"api/line_searches/#LineSearches.jl","page":"LineSearches.jl","title":"LineSearches.jl","text":"This is a extension for importing line search algorithms from LineSearches into the SciML interface. Note that these solvers do not come by default, and thus one needs to install the package before using these solvers:\n\nusing Pkg\nPkg.add(\"LineSearches\")\nusing LineSearches, LineSearch","category":"section"},{"location":"api/line_searches/#Line-Search-API","page":"LineSearches.jl","title":"Line Search API","text":"tip: Tip\nUnlike LineSearches.jl, we automatically construct the gradient/jacobian functionality from the problem specification using automatic differentiation (if analytic versions are not provided).","category":"section"},{"location":"api/line_searches/#LineSearch.LineSearchesJL","page":"LineSearches.jl","title":"LineSearch.LineSearchesJL","text":"LineSearchesJL(; method = LineSearches.Static(), autodiff = nothing,\n    initial_alpha = true)\n\nWrapper over algorithms from LineSearches.jl. Allows automatic construction of the objective functions for the line search algorithms utilizing automatic differentiation for fast VJPs or JVPs.\n\nwarning: Warning\nNeeds LineSearches.jl to be explicitly loaded before using this functionality.\n\nArguments\n\nmethod: the line search algorithm to use. Defaults to method = LineSearches.Static(), which means that the step size is fixed to the value of alpha.\nautodiff: the automatic differentiation backend to use for the line search. Must be specified if analytic jacobian/jvp/vjp is not available.\ninitial_alpha: the initial step size to use. Defaults to true (which is equivalent to 1).\n\n\n\n\n\n","category":"type"},{"location":"api/native/#Native-Line-Search-Algorithms","page":"Native Functionalities","title":"Native Line Search Algorithms","text":"","category":"section"},{"location":"api/native/#No-Line-Search","page":"Native Functionalities","title":"No Line Search","text":"","category":"section"},{"location":"api/native/#Derivative-Free-Line-Searches","page":"Native Functionalities","title":"Derivative-Free Line Searches","text":"","category":"section"},{"location":"api/native/#Backtracking-Line-Search","page":"Native Functionalities","title":"Backtracking Line Search","text":"","category":"section"},{"location":"api/native/#LineSearch.NoLineSearch","page":"Native Functionalities","title":"LineSearch.NoLineSearch","text":"NoLineSearch(alpha)\n\nDon't perform a line search. Just return the initial step length of alpha.\n\n\n\n\n\n","category":"type"},{"location":"api/native/#LineSearch.LiFukushimaLineSearch","page":"Native Functionalities","title":"LineSearch.LiFukushimaLineSearch","text":"LiFukushimaLineSearch(; lambda_0 = 1, beta = 1 // 2, sigma_1 = 1 // 1000,\n    sigma_2 = 1 // 1000, eta = 1 // 10, nan_maxiters::Int = 5, maxiters::Int = 100)\n\nA derivative-free line search and global convergence of Broyden-like method for nonlinear equations [1].\n\ntip: Tip\nFor static arrays and numbers if nan_maxiters is either nothing or missing, we provide a fully non-allocating implementation of the algorithm, that can be used inside GPU kernels. However, this particular version doesn't support stats and reinit! and those will be ignored. Additionally, we fix the initial alpha for the search to be 1.\n\n\n\n\n\n","category":"type"},{"location":"api/native/#LineSearch.RobustNonMonotoneLineSearch","page":"Native Functionalities","title":"LineSearch.RobustNonMonotoneLineSearch","text":"RobustNonMonotoneLineSearch(; gamma = 1 // 10000, sigma_0 = 1, M::Int = 10,\n    tau_min = 1 // 10, tau_max = 1 // 2, n_exp::Int = 2, maxiters::Int = 100,\n    η_strategy = (fn₁, n, uₙ, fₙ) -> fn₁ / n^2)\n\nRobust NonMonotone Line Search is a derivative free line search method from DF Sane [2].\n\nKeyword Arguments\n\nM: The monotonicity of the algorithm is determined by a this positive integer. A value of 1 for M would result in strict monotonicity in the decrease of the L2-norm of the function f. However, higher values allow for more flexibility in this reduction. Despite this, the algorithm still ensures global convergence through the use of a non-monotone line-search algorithm that adheres to the Grippo-Lampariello-Lucidi condition. Values in the range of 5 to 20 are usually sufficient, but some cases may call for a higher value of M. The default setting is 10.\ngamma: a parameter that influences if a proposed step will be accepted. Higher value of gamma will make the algorithm more restrictive in accepting steps. Defaults to 1e-4.\ntau_min: if a step is rejected the new step size will get multiplied by factor, and this parameter is the minimum value of that factor. Defaults to 0.1.\ntau_max: if a step is rejected the new step size will get multiplied by factor, and this parameter is the maximum value of that factor. Defaults to 0.5.\nn_exp: the exponent of the loss, i.e. f_n=F(x_n)^n_exp. The paper uses n_exp ∈ {1, 2}. Defaults to 2.\nη_strategy:  function to determine the parameter η, which enables growth of f_n^2. Called as η = η_strategy(fn_1, n, x_n, f_n) with fn_1 initialized as fn_1=f(x_1)^n_exp, n is the iteration number, x_n is the current x-value and f_n the current residual. Should satisfy η  0 and ₖ ηₖ  . Defaults to fn_1  n^2.\nmaxiters: the maximum number of iterations allowed for the inner loop of the algorithm. Defaults to 100.\n\n\n\n\n\n","category":"type"},{"location":"api/native/#LineSearch.BackTracking","page":"Native Functionalities","title":"LineSearch.BackTracking","text":"BackTracking(; autodiff = nothing, c_1 = 1e-4, ρ_hi = 0.5, ρ_lo = 0.1,\n    order = 3,\n    maxstep = Inf, initial_alpha = true)\n\nBackTracking line search algorithm based on the implementation in LineSearches.jl.\n\nBackTracking specifies a backtracking line-search that uses a quadratic or cubic interpolant to determine the reduction in step-size.\n\nE.g., if f(α) > f(0) + c₁ α f'(0), then the quadratic interpolant of f(0), f'(0), f(α) has a minimiser α' in the open interval (0, α). More strongly, there exists a factor ρ = ρ(c₁) such that α' ≦ ρ α.\n\nThis is a modification of the algorithm described in Nocedal Wright (2nd ed), Sec. 3.5.\n\nautodiff is the automatic differentiation backend to use for the line search. This is only used for the derivative of the objective function at the current step size. autodiff must be specified if analytic jacobian/jvp/vjp is not available.\n\n\n\n\n\n","category":"type"},{"location":"#LineSearch.jl:-High-Performance-Unified-Line-Search-Algorithms","page":"LineSearch.jl: High-Performance Unified Line Search Algorithms","title":"LineSearch.jl: High-Performance Unified Line Search Algorithms","text":"LineSearch.jl is a unified interface for the line search packages of Julia. The package includes its own high-performance line search algorithms.\n\nPerformance is key: the current methods are made to be highly performant on scalar and statically sized small problems, with options for large-scale systems. If you run into any performance issues, please file an issue.\n\nwarning: Warning\nCurrently this package is meant to be more developer focused. Most users are recommended to use this functionality via NonlinearSolve.jl. Support for other packages in the ecosystem like Optimization.jl are planned for the future.","category":"section"},{"location":"#Installation","page":"LineSearch.jl: High-Performance Unified Line Search Algorithms","title":"Installation","text":"To install LineSearch.jl, use the Julia package manager:\n\nusing Pkg\nPkg.add(\"LineSearch\")","category":"section"},{"location":"#Contributing","page":"LineSearch.jl: High-Performance Unified Line Search Algorithms","title":"Contributing","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"section"},{"location":"#Reproducibility","page":"LineSearch.jl: High-Performance Unified Line Search Algorithms","title":"Reproducibility","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>\n\nusing Pkg # hide\nPkg.status() # hide\n\n</details>\n\n<details><summary>and using this machine and Julia version.</summary>\n\nusing InteractiveUtils # hide\nversioninfo() # hide\n\n</details>\n\n<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>\n\nusing Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide\n\n</details>\n\nusing TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" *\n                name *\n                \".jl/tree/gh-pages/v\" *\n                version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" *\n               name *\n               \".jl/tree/gh-pages/v\" *\n               version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"section"}]
}
